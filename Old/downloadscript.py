from nltk.tokenize import word_tokenize

text = "This is an example sentence. It showcases word tokenization."

tokens = word_tokenize(text)

print(tokens)
